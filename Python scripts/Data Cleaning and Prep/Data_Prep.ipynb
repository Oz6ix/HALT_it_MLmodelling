{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f81db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('HALT_score_included_cleaned.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055c1bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ce3432",
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are so many missing values in many columns, let's see for the decision of whether we will keep in analysis or not\n",
    "# Calculate the percentage of missing values for each column\n",
    "missing_percentage = df.isnull().mean() * 100\n",
    "columns_to_drop = missing_percentage[missing_percentage > 80].index.tolist()\n",
    "print(\"Columns dropped:\", columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c9cccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#except 'timerandtodeath','causedeath','causedeathother','stillinhospday28','rebleedingnum'\n",
    "#other data columns are not needed for my analysis and will drop those columns as part of data cleaning, will update\n",
    "#columsn to drop meaning\n",
    "essential_columns = ['timerandtodeath', 'causedeath', 'causedeathother', 'stillinhospday28', 'rebleedingnum','isserious1','isserious1']\n",
    "columns_to_drop2 = missing_percentage[missing_percentage > 80].index.difference(essential_columns).tolist()\n",
    "cleaned_data = df.drop(columns=columns_to_drop2)\n",
    "print(cleaned_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1c546e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving final cleanded dataset\n",
    "cleaned_data.to_csv('final_cleaned_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e3c15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = cleaned_data.isna().sum()\n",
    "missing_data = missing_data[missing_data > 0] # Filter columns with missing values \n",
    "print(missing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d828c09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b386e15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of categorical data\n",
    "for col in cleaned_data.select_dtypes(include=['object']).columns: \n",
    "    print(f\"{col}:\\n{cleaned_data[col].value_counts()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d65595",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------Different methodology below---------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8707a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Visualize missing data\n",
    "sns.heatmap(cleaned_data.isnull(), cbar=False, cmap='viridis')\n",
    "plt.title('Missing Data Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324ea050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('HALT_score_included_cleaned.csv', low_memory=False)\n",
    "\n",
    "# Encode the 'rebleeding' column to numerical values\n",
    "cleaned_data = df.copy()\n",
    "cleaned_data['rebleeding_encoded'] = cleaned_data['rebleeding'].map({'No': 0, 'Yes': 1})\n",
    "\n",
    "# Verify the encoding\n",
    "print(cleaned_data[['rebleeding', 'rebleeding_encoded']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcac248c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots for numerical variables vs a specific key outcome1\n",
    "key_outcome1 = 'rebleeding_encoded'\n",
    "numerical_cols = cleaned_data.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "for col in numerical_cols:\n",
    "    if col != key_outcome1:\n",
    "        sns.lmplot(x=col, y=key_outcome1, data=cleaned_data, aspect=1.5)\n",
    "        plt.title(f'{col} vs {key_outcome1}')\n",
    "        plt.show()\n",
    "\n",
    "# Box plots for numerical variables vs key outcome\n",
    "for col in numerical_cols:\n",
    "    if col != key_outcome1:\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        sns.boxplot(x=key_outcome1, y=col, data=cleaned_data)\n",
    "        plt.title(f'{key_outcome1} vs {col}')\n",
    "        plt.show()\n",
    "\n",
    "# Correlation and Pair Plots\n",
    "plt.figure(figsize=(16, 12))\n",
    "sns.heatmap(cleaned_data.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Pair plot for numerical columns\n",
    "sns.pairplot(cleaned_data[numerical_cols])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c27539",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e29ae45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bivariate Analysis\n",
    "# Scatter plots for numerical variables vs a specific key outcome2 'causedeath', create a binary outcome column\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Create a binary outcome column for death\n",
    "cleaned_data['death'] = cleaned_data['causedeath'].notnull().astype(int)\n",
    "\n",
    "# Verify the new column\n",
    "print(cleaned_data[['causedeath', 'death']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9523c83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_outcome2 = 'death'\n",
    "numerical_cols = cleaned_data.select_dtypes(include=['int64', 'float64']).columns\n",
    "# Scatter plots for numerical variables vs a specific key outcome2\n",
    "for col in numerical_cols:\n",
    "    if col != key_outcome2:\n",
    "        sns.lmplot(x=col, y=key_outcome2, data=cleaned_data, aspect=1.5)\n",
    "        plt.title(f'{col} vs {key_outcome2}')\n",
    "        plt.show()\n",
    "\n",
    "# Box plots for numerical variables vs key outcome2\n",
    "for col in numerical_cols:\n",
    "    if col != key_outcome2:\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        sns.boxplot(x=key_outcome2, y=col, data=cleaned_data)\n",
    "        plt.title(f'{key_outcome2} vs {col}')\n",
    "        plt.show()\n",
    "        \n",
    "# Heatmaps for categorical variables vs outcome3\n",
    "categorical_cols = cleaned_data.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    count_matrix = pd.crosstab(index=cleaned_data[col], columns=cleaned_data[key_outcome2])\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(count_matrix, annot=True, fmt='d', cmap='coolwarm')\n",
    "    plt.title(f'Heatmap of {col} by {key_outcome2}')\n",
    "    plt.xlabel(key_outcome2)\n",
    "    plt.ylabel(col)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9544ec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bivariate Analysis\n",
    "# Scatter plots for numerical variables vs a specific key outcome3 'stillinhospday28', create a binary outcome column\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Create a binary outcome column for death\n",
    "cleaned_data['long_hospital_stay'] = cleaned_data['stillinhospday28'].notnull().astype(int)\n",
    "\n",
    "# Verify the new column\n",
    "print(cleaned_data[['long_hospital_stay', 'stillinhospday28']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d356cc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_outcome3 = 'long_hospital_stay'\n",
    "numerical_cols = cleaned_data.select_dtypes(include=['int64', 'float64']).columns\n",
    "# Scatter plots for numerical variables vs a specific key outcome3\n",
    "for col in numerical_cols:\n",
    "    if col != key_outcome3:\n",
    "        sns.lmplot(x=col, y=key_outcome3, data=cleaned_data, aspect=1.5)\n",
    "        plt.title(f'{col} vs {key_outcome3}')\n",
    "        plt.show()\n",
    "\n",
    "# Box plots for numerical variables vs key outcome3\n",
    "for col in numerical_cols:\n",
    "    if col != key_outcome3:\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        sns.boxplot(x=key_outcome3, y=col, data=cleaned_data)\n",
    "        plt.title(f'{key_outcome3} vs {col}')\n",
    "        plt.show()\n",
    "        \n",
    "# Heatmaps for categorical variables vs outcome3\n",
    "categorical_cols = cleaned_data.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    count_matrix = pd.crosstab(index=cleaned_data[col], columns=cleaned_data[key_outcome3])\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(count_matrix, annot=True, fmt='d', cmap='coolwarm')\n",
    "    plt.title(f'Heatmap of {col} by {key_outcome3}')\n",
    "    plt.xlabel(key_outcome3)\n",
    "    plt.ylabel(col)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c0e1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix\n",
    "plt.figure(figsize=(16, 12))\n",
    "sns.heatmap(cleaned_data.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Pair plot for numerical columns\n",
    "sns.pairplot(cleaned_data[numerical_cols])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3dd3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Importance Analysis_step one_ data preparation\n",
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned dataset\n",
    "df = pd.read_csv('HALT_score_included_cleaned.csv', low_memory=False)\n",
    "\n",
    "# Drop columns with more than 80% missing values, except essential ones\n",
    "essential_columns = ['timerandtodeath', 'causedeath', 'causedeathother', 'stillinhospday28', 'rebleedingnum']\n",
    "missing_percentage = df.isnull().mean() * 100\n",
    "columns_to_drop2 = missing_percentage[missing_percentage > 80].index.difference(essential_columns).tolist()\n",
    "cleaned_data = df.drop(columns=columns_to_drop2)\n",
    "\n",
    "# Impute missing values for numerical columns with median\n",
    "for col in cleaned_data.select_dtypes(include=['int64', 'float64']).columns:\n",
    "    cleaned_data[col].fillna(cleaned_data[col].median(), inplace=True)\n",
    "\n",
    "# Impute missing values for categorical columns with mode\n",
    "for col in cleaned_data.select_dtypes(include=['object']).columns:\n",
    "    cleaned_data[col].fillna(cleaned_data[col].mode()[0], inplace=True)\n",
    "\n",
    "# Encode categorical variables\n",
    "cleaned_data_encoded = pd.get_dummies(cleaned_data, drop_first=True)\n",
    "\n",
    "# Add binary outcomes for analysis\n",
    "if 'rebleeding' in cleaned_data.columns:\n",
    "    cleaned_data_encoded['rebleeding_encoded'] = cleaned_data['rebleeding'].map({'No': 0, 'Yes': 1})\n",
    "if 'timerandtodeath' in cleaned_data.columns:\n",
    "    cleaned_data_encoded['death'] = cleaned_data['timerandtodeath'].notnull().astype(int)\n",
    "if 'stillinhospday28' in cleaned_data.columns:\n",
    "    cleaned_data_encoded['long_hospital_stay'] = cleaned_data['stillinhospday28'].notnull().astype(int)\n",
    "\n",
    "# Verify the encoding\n",
    "print(cleaned_data_encoded[['rebleeding_encoded', 'death', 'long_hospital_stay']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b2058c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Define Features and Target Variables\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features (X) and target (y) for 'rebleeding' outcome\n",
    "X_rebleeding = cleaned_data_encoded.drop(columns=['rebleeding_encoded', 'death', 'long_hospital_stay'], errors='ignore')\n",
    "y_rebleeding = cleaned_data_encoded['rebleeding_encoded']\n",
    "\n",
    "# Split the dataset into training and testing sets for 'rebleeding'\n",
    "X_train_rebleeding, X_test_rebleeding, y_train_rebleeding, y_test_rebleeding = train_test_split(X_rebleeding, y_rebleeding, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define features (X) and target (y) for 'death' outcome\n",
    "y_death = cleaned_data_encoded['death']\n",
    "\n",
    "# Split the dataset into training and testing sets for 'death'\n",
    "X_train_death, X_test_death, y_train_death, y_test_death = train_test_split(X_rebleeding, y_death, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define features (X) and target (y) for 'long hospital stay' outcome\n",
    "y_long_hospital_stay = cleaned_data_encoded['long_hospital_stay']\n",
    "\n",
    "# Split the dataset into training and testing sets for 'long hospital stay'\n",
    "X_train_long_hospital_stay, X_test_long_hospital_stay, y_train_long_hospital_stay, y_test_long_hospital_stay = train_test_split(X_rebleeding, y_long_hospital_stay, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1a8450",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3: Train the Model and Perform Feature Importance Analysis\n",
    "#Feature Importance for Rebleeding\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Train a Random Forest model for 'rebleeding' outcome\n",
    "rf_model_rebleeding = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model_rebleeding.fit(X_train_rebleeding, y_train_rebleeding)\n",
    "\n",
    "# Extract feature importances\n",
    "feature_importances_rebleeding = rf_model_rebleeding.feature_importances_\n",
    "features_rebleeding = X_rebleeding.columns\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "importance_df_rebleeding = pd.DataFrame({'Feature': features_rebleeding, 'Importance': feature_importances_rebleeding})\n",
    "importance_df_rebleeding = importance_df_rebleeding.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Filter to display only the top N most important features\n",
    "top_n = 5  # You can adjust this value as needed\n",
    "importance_df_rebleeding_top = importance_df_rebleeding.head(top_n)\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_df_rebleeding)\n",
    "plt.title('Feature Importances for Rebleeding from Random Forest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4952b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Importance for Death\n",
    "# Train a Random Forest model for 'death' outcome\n",
    "rf_model_death = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model_death.fit(X_train_death, y_train_death)\n",
    "\n",
    "# Extract feature importances\n",
    "feature_importances_death = rf_model_death.feature_importances_\n",
    "features_death = X_rebleeding.columns\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "importance_df_death = pd.DataFrame({'Feature': features_death, 'Importance': feature_importances_death})\n",
    "importance_df_death = importance_df_death.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Filter to display only the top N most important features\n",
    "importance_df_death_top = importance_df_death.head(top_n)\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_df_death)\n",
    "plt.title('Feature Importances for Death from Random Forest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646116df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Importance for Long Hospital Stay\n",
    "# Train a Random Forest model for 'long hospital stay' outcome\n",
    "rf_model_long_hospital_stay = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model_long_hospital_stay.fit(X_train_long_hospital_stay, y_train_long_hospital_stay)\n",
    "\n",
    "# Extract feature importances\n",
    "feature_importances_long_hospital_stay = rf_model_long_hospital_stay.feature_importances_\n",
    "features_long_hospital_stay = X_rebleeding.columns\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "importance_df_long_hospital_stay = pd.DataFrame({'Feature': features_long_hospital_stay, 'Importance': feature_importances_long_hospital_stay})\n",
    "importance_df_long_hospital_stay = importance_df_long_hospital_stay.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Filter to display only the top N most important features\n",
    "importance_df_long_hospital_stay_top = importance_df_long_hospital_stay.head(top_n)\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_df_long_hospital_stay)\n",
    "plt.title('Feature Importances for Long Hospital Stay from Random Forest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baa7a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#images are not readable, trying new code \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Train a Random Forest model for 'rebleeding' outcome\n",
    "rf_model_rebleeding = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model_rebleeding.fit(X_train_rebleeding, y_train_rebleeding)\n",
    "\n",
    "# Extract feature importances\n",
    "feature_importances_rebleeding = rf_model_rebleeding.feature_importances_\n",
    "features_rebleeding = X_rebleeding.columns\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "importance_df_rebleeding = pd.DataFrame({'Feature': features_rebleeding, 'Importance': feature_importances_rebleeding})\n",
    "importance_df_rebleeding = importance_df_rebleeding.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Filter to display only the top N most important features\n",
    "top_n = 10  # You can adjust this value as needed\n",
    "importance_df_rebleeding_top = importance_df_rebleeding.head(top_n)\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(15, 10))  # Increase figure size\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_df_rebleeding_top)\n",
    "plt.title('Top Feature Importances for Rebleeding from Random Forest', fontsize=16)\n",
    "plt.xlabel('Importance', fontsize=14)\n",
    "plt.ylabel('Feature', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea0e626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest model for 'death' outcome\n",
    "rf_model_death = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model_death.fit(X_train_death, y_train_death)\n",
    "\n",
    "# Extract feature importances\n",
    "feature_importances_death = rf_model_death.feature_importances_\n",
    "features_death = X_rebleeding.columns\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "importance_df_death = pd.DataFrame({'Feature': features_death, 'Importance': feature_importances_death})\n",
    "importance_df_death = importance_df_death.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Filter to display only the top N most important features\n",
    "top_n = 10  # You can adjust this value as needed\n",
    "importance_df_death_top = importance_df_death.head(top_n)\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(15, 10))  # Increase figure size\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_df_death_top)\n",
    "plt.title('Top Feature Importances for Death from Random Forest', fontsize=16)\n",
    "plt.xlabel('Importance', fontsize=14)\n",
    "plt.ylabel('Feature', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate feature names\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3380f735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest model for 'long hospital stay' outcome\n",
    "rf_model_long_hospital_stay = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model_long_hospital_stay.fit(X_train_long_hospital_stay, y_train_long_hospital_stay)\n",
    "\n",
    "# Extract feature importances\n",
    "feature_importances_long_hospital_stay = rf_model_long_hospital_stay.feature_importances_\n",
    "features_long_hospital_stay = X_rebleeding.columns\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "importance_df_long_hospital_stay = pd.DataFrame({'Feature': features_long_hospital_stay, 'Importance': feature_importances_long_hospital_stay})\n",
    "importance_df_long_hospital_stay = importance_df_long_hospital_stay.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Filter to display only the top N most important features\n",
    "importance_df_long_hospital_stay_top = importance_df_long_hospital_stay.head(top_n)\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(15, 10))  # Increase figure size\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_df_long_hospital_stay_top)\n",
    "plt.title('Top Feature Importances for Long Hospital Stay from Random Forest', fontsize=16)\n",
    "plt.xlabel('Importance', fontsize=14)\n",
    "plt.ylabel('Feature', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate feature names\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48efd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load the cleaned dataset\n",
    "df = pd.read_csv('HALT_score_included_cleaned.csv', low_memory=False)\n",
    "\n",
    "# Drop columns with more than 80% missing values, except essential ones\n",
    "essential_columns = ['timerandtodeath', 'causedeath', 'causedeathother', 'stillinhospday28', 'rebleedingnum']\n",
    "missing_percentage = df.isnull().mean() * 100\n",
    "columns_to_drop2 = missing_percentage[missing_percentage > 80].index.difference(essential_columns).tolist()\n",
    "cleaned_data = df.drop(columns=columns_to_drop2)\n",
    "\n",
    "# Impute missing values for numerical columns with median\n",
    "for col in cleaned_data.select_dtypes(include=['int64', 'float64']).columns:\n",
    "    cleaned_data[col].fillna(cleaned_data[col].median(), inplace=True)\n",
    "\n",
    "# Impute missing values for categorical columns with mode\n",
    "for col in cleaned_data.select_dtypes(include=['object']).columns:\n",
    "    cleaned_data[col].fillna(cleaned_data[col].mode()[0], inplace=True)\n",
    "\n",
    "# Encode categorical variables\n",
    "cleaned_data_encoded = pd.get_dummies(cleaned_data, drop_first=True)\n",
    "\n",
    "# Add binary outcomes for analysis\n",
    "cleaned_data_encoded['rebleeding_encoded'] = cleaned_data['rebleeding'].map({'No': 0, 'Yes': 1})\n",
    "cleaned_data_encoded['death'] = cleaned_data['timerandtodeath'].notnull().astype(int)\n",
    "cleaned_data_encoded['long_hospital_stay'] = cleaned_data['stillinhospday28'].notnull().astype(int)\n",
    "\n",
    "# Remove features with high cardinality\n",
    "cardinality_threshold = 50  # Adjust as needed\n",
    "high_cardinality_cols = [col for col in cleaned_data_encoded.columns if cleaned_data_encoded[col].nunique() > cardinality_threshold]\n",
    "cleaned_data_encoded.drop(columns=high_cardinality_cols, inplace=True)\n",
    "\n",
    "# Verify the encoding\n",
    "print(cleaned_data_encoded[['rebleeding_encoded', 'death', 'long_hospital_stay']].head())\n",
    "\n",
    "# Define features (X) and target (y) for 'rebleeding' outcome\n",
    "X_rebleeding = cleaned_data_encoded.drop(columns=['rebleeding_encoded', 'death', 'long_hospital_stay', 'timerandtodeath'], errors='ignore')\n",
    "y_rebleeding = cleaned_data_encoded['rebleeding_encoded']\n",
    "\n",
    "# Split the dataset into training and testing sets for 'rebleeding'\n",
    "X_train_rebleeding, X_test_rebleeding, y_train_rebleeding, y_test_rebleeding = train_test_split(X_rebleeding, y_rebleeding, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest model for 'rebleeding' outcome\n",
    "rf_model_rebleeding = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model_rebleeding.fit(X_train_rebleeding, y_train_rebleeding)\n",
    "\n",
    "# Extract feature importances\n",
    "feature_importances_rebleeding = rf_model_rebleeding.feature_importances_\n",
    "features_rebleeding = X_rebleeding.columns\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "importance_df_rebleeding = pd.DataFrame({'Feature': features_rebleeding, 'Importance': feature_importances_rebleeding})\n",
    "importance_df_rebleeding = importance_df_rebleeding.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Filter to display only the top N most important features\n",
    "top_n = 10  # You can adjust this value as needed\n",
    "importance_df_rebleeding_top = importance_df_rebleeding.head(top_n)\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(15, 10))  # Increase figure size\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_df_rebleeding_top)\n",
    "plt.title('Top Feature Importances for Rebleeding from Random Forest', fontsize=16)\n",
    "plt.xlabel('Importance', fontsize=14)\n",
    "plt.ylabel('Feature', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate feature names\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ee51c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y) for 'death' outcome\n",
    "X_death = cleaned_data_encoded.drop(columns=['death', 'rebleeding_encoded', 'long_hospital_stay', 'timerandtodeath'], errors='ignore')\n",
    "y_death = cleaned_data_encoded['death']\n",
    "\n",
    "# Split the dataset into training and testing sets for 'death'\n",
    "X_train_death, X_test_death, y_train_death, y_test_death = train_test_split(X_death, y_death, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest model for 'death' outcome\n",
    "rf_model_death = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model_death.fit(X_train_death, y_train_death)\n",
    "\n",
    "# Extract feature importances\n",
    "feature_importances_death = rf_model_death.feature_importances_\n",
    "features_death = X_death.columns\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "importance_df_death = pd.DataFrame({'Feature': features_death, 'Importance': feature_importances_death})\n",
    "importance_df_death = importance_df_death.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Filter to display only the top N most important features\n",
    "importance_df_death_top = importance_df_death.head(top_n)\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(15, 10))  # Increase figure size\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_df_death_top)\n",
    "plt.title('Top Feature Importances for Death from Random Forest', fontsize=16)\n",
    "plt.xlabel('Importance', fontsize=14)\n",
    "plt.ylabel('Feature', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate feature names\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560fdb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y) for 'long hospital stay' outcome\n",
    "X_long_hospital_stay = cleaned_data_encoded.drop(columns=['long_hospital_stay', 'rebleeding_encoded', 'death'], errors='ignore')\n",
    "y_long_hospital_stay = cleaned_data_encoded['long_hospital_stay']\n",
    "\n",
    "# Split the dataset into training and testing sets for 'long hospital stay'\n",
    "X_train_long_hospital_stay, X_test_long_hospital_stay, y_train_long_hospital_stay, y_test_long_hospital_stay = train_test_split(X_long_hospital_stay, y_long_hospital_stay, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest model for 'long hospital stay' outcome\n",
    "rf_model_long_hospital_stay = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model_long_hospital_stay.fit(X_train_long_hospital_stay, y_train_long_hospital_stay)\n",
    "\n",
    "# Extract feature importances\n",
    "feature_importances_long_hospital_stay = rf_model_long_hospital_stay.feature_importances_\n",
    "features_long_hospital_stay = X_long_hospital_stay.columns\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "importance_df_long_hospital_stay = pd.DataFrame({'Feature': features_long_hospital_stay, 'Importance': feature_importances_long_hospital_stay})\n",
    "importance_df_long_hospital_stay = importance_df_long_hospital_stay.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Filter to display only the top N most important features\n",
    "importance_df_long_hospital_stay_top = importance_df_long_hospital_stay.head(top_n)\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(15, 10))  # Increase figure size\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_df_long_hospital_stay_top)\n",
    "plt.title('Top Feature Importances for Long Hospital Stay from Random Forest', fontsize=16)\n",
    "plt.xlabel('Importance', fontsize=14)\n",
    "plt.ylabel('Feature', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate feature names\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1f15e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('HALT_score_included_cleaned.csv', low_memory=False)\n",
    "\n",
    "# Drop columns with more than 80% missing values, except essential ones\n",
    "essential_columns = ['timerandtodeath', 'causedeath', 'causedeathother', 'stillinhospday28', 'rebleedingnum']\n",
    "missing_percentage = df.isnull().mean() * 100\n",
    "columns_to_drop2 = missing_percentage[missing_percentage > 80].index.difference(essential_columns).tolist()\n",
    "cleaned_data = df.drop(columns=columns_to_drop2)\n",
    "\n",
    "# Impute missing values for numerical columns with median\n",
    "for col in cleaned_data.select_dtypes(include=['int64', 'float64']).columns:\n",
    "    cleaned_data[col].fillna(cleaned_data[col].median(), inplace=True)\n",
    "\n",
    "# Impute missing values for categorical columns with mode\n",
    "for col in cleaned_data.select_dtypes(include=['object']).columns:\n",
    "    cleaned_data[col].fillna(cleaned_data[col].mode()[0], inplace=True)\n",
    "\n",
    "# Encode categorical variables\n",
    "cleaned_data_encoded = pd.get_dummies(cleaned_data, drop_first=True)\n",
    "\n",
    "# Add binary outcomes for analysis\n",
    "cleaned_data_encoded['rebleeding_encoded'] = cleaned_data['rebleeding'].map({'No': 0, 'Yes': 1})\n",
    "cleaned_data_encoded['death'] = cleaned_data['timerandtodeath'].notnull().astype(int)\n",
    "cleaned_data_encoded['long_hospital_stay'] = cleaned_data['stillinhospday28'].notnull().astype(int)\n",
    "\n",
    "# Verify the encoding\n",
    "print(cleaned_data_encoded[['rebleeding_encoded', 'death', 'long_hospital_stay']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86508f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y) for 'rebleeding' outcome\n",
    "X_rebleeding = cleaned_data_encoded.drop(columns=['rebleeding_encoded', 'death', 'long_hospital_stay', 'timerandtodeath'], errors='ignore')\n",
    "y_rebleeding = cleaned_data_encoded['rebleeding_encoded']\n",
    "\n",
    "# Split the dataset into training and testing sets for 'rebleeding'\n",
    "X_train_rebleeding, X_test_rebleeding, y_train_rebleeding, y_test_rebleeding = train_test_split(X_rebleeding, y_rebleeding, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest model for 'rebleeding' outcome\n",
    "rf_model_rebleeding = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model_rebleeding.fit(X_train_rebleeding, y_train_rebleeding)\n",
    "\n",
    "# Extract feature importances\n",
    "feature_importances_rebleeding = rf_model_rebleeding.feature_importances_\n",
    "features_rebleeding = X_rebleeding.columns\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "importance_df_rebleeding = pd.DataFrame({'Feature': features_rebleeding, 'Importance': feature_importances_rebleeding})\n",
    "importance_df_rebleeding = importance_df_rebleeding.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Filter to display only the top N most important features\n",
    "top_n = 10  # You can adjust this value as needed\n",
    "importance_df_rebleeding_top = importance_df_rebleeding.head(top_n)\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(15, 10))  # Increase figure size\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_df_rebleeding_top)\n",
    "plt.title('Top Feature Importances for Rebleeding from Random Forest', fontsize=16)\n",
    "plt.xlabel('Importance', fontsize=14)\n",
    "plt.ylabel('Feature', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate feature names\n",
    "plt.show()\n",
    "\n",
    "# Define features (X) and target (y) for 'death' outcome\n",
    "X_death = cleaned_data_encoded.drop(columns=['death', 'rebleeding_encoded', 'long_hospital_stay', 'timerandtodeath'], errors='ignore')\n",
    "y_death = cleaned_data_encoded['death']\n",
    "\n",
    "# Split the dataset into training and testing sets for 'death'\n",
    "X_train_death, X_test_death, y_train_death, y_test_death = train_test_split(X_death, y_death, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest model for 'death' outcome\n",
    "rf_model_death = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model_death.fit(X_train_death, y_train_death)\n",
    "\n",
    "# Extract feature importances\n",
    "feature_importances_death = rf_model_death.feature_importances_\n",
    "features_death = X_death.columns\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "importance_df_death = pd.DataFrame({'Feature': features_death, 'Importance': feature_importances_death})\n",
    "importance_df_death = importance_df_death.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Filter to display only the top N most important features\n",
    "importance_df_death_top = importance_df_death.head(top_n)\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(15, 10))  # Increase figure size\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_df_death_top)\n",
    "plt.title('Top Feature Importances for Death from Random Forest', fontsize=16)\n",
    "plt.xlabel('Importance', fontsize=14)\n",
    "plt.ylabel('Feature', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate feature names\n",
    "plt.show()\n",
    "\n",
    "# Define features (X) and target (y) for 'long hospital stay' outcome\n",
    "X_long_hospital_stay = cleaned_data_encoded.drop(columns=['long_hospital_stay', 'rebleeding_encoded', 'death', 'timerandtodeath'], errors='ignore')\n",
    "y_long_hospital_stay = cleaned_data_encoded['long_hospital_stay']\n",
    "\n",
    "# Split the dataset into training and testing sets for 'long hospital stay'\n",
    "X_train_long_hospital_stay, X_test_long_hospital_stay, y_train_long_hospital_stay, y_test_long_hospital_stay = train_test_split(X_long_hospital_stay, y_long_hospital_stay, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest model for 'long hospital stay' outcome\n",
    "rf_model_long_hospital_stay = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model_long_hospital_stay.fit(X_train_long_hospital_stay, y_train_long_hospital_stay)\n",
    "\n",
    "# Extract feature importances\n",
    "feature_importances_long_hospital_stay = rf_model_long_hospital_stay.feature_importances_\n",
    "features_long_hospital_stay = X_long_hospital_stay.columns\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "importance_df_long_hospital_stay = pd.DataFrame({'Feature': features_long_hospital_stay, 'Importance': feature_importances_long_hospital_stay})\n",
    "importance_df_long_hospital_stay = importance_df_long_hospital_stay.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Filter to display only the top N most important features\n",
    "importance_df_long_hospital_stay_top = importance_df_long_hospital_stay.head(top_n)\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(15, 10))  # Increase figure size\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_df_long_hospital_stay_top)\n",
    "plt.title('Top Feature Importances for Long Hospital Stay from Random Forest', fontsize=16)\n",
    "plt.xlabel('Importance', fontsize=14)\n",
    "plt.ylabel('Feature', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate feature names\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e9ccb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179eec74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
